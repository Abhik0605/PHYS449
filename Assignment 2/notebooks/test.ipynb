{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd0154ae20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('../inputs/even_mnist.csv', header = None, sep = ' ')\n",
    "\n",
    "\n",
    "test_data = data.sample(n=3000, random_state=1)\n",
    "train_data = data.drop(test_data.columns, axis=1)\n",
    "\n",
    "test_labels = data.iloc[-1 , :]\n",
    "train_labels = data.iloc[-1 , :]\n",
    "\n",
    "test_data = test_data/255\n",
    "train_data = train_data/255\n",
    "\n",
    "test_data.drop(test_data.tail(1).index,inplace=True)\n",
    "train_data.drop(train_data.tail(1).index,inplace=True)\n",
    "\n",
    "foo = np.array(train_data[5])\n",
    "plt.imshow(np.reshape(foo, (14,14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29487</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29488</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29489</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29491</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26492 rows × 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  187  188  189  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "5        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "29487    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "29488    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "29489    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "29490    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "29491    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "       190  191  192  193  194  195  196  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    4  \n",
       "3        0    0    0    0    0    0    4  \n",
       "4        0    0    0    0    0    0    6  \n",
       "5        0    0    0    0    0    0    2  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "29487    0    0    0    0    0    0    8  \n",
       "29488    0    0    0    0    0    0    2  \n",
       "29489    0    0    0    0    0    0    8  \n",
       "29490    0    0    0    0    0    0    6  \n",
       "29491    0    0    0    0    0    0    8  \n",
       "\n",
       "[26492 rows x 197 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data.sample(n=3000, random_state=1)\n",
    "train_data = data.drop(test_data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../inputs/even_mnist.csv', header = None, sep = ' ')\n",
    "images = data.iloc[:,:-1]\n",
    "labels = data.iloc[:,-1:]\n",
    "np.array(images.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(196, 98) \n",
    "        self.fc2 = nn.Linear(98, 84)\n",
    "        self.fc3 = nn.Linear(84, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_matrix = F.one_hot(torch.arange(0, 5) , num_classes=5)\n",
    "\n",
    "def one_hot(target, one_hot):\n",
    "    new_target_vector = one_hot[int(target/2)]\n",
    "    return new_target_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.from_numpy(np.array(train_labels))\n",
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-040632623555>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2006, 0.1933, 0.2079, 0.2107, 0.1874]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.from_numpy(np.array(train_data.transpose()))\n",
    "foo = torch.reshape(inputs[1].float(), (1,-1))\n",
    "x = model.forward(foo)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-040632623555>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got numpy.int64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-5f82187555f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         print('\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mobj_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#         print(model.forward(input_temp))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         print('\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got numpy.int64)"
     ]
    }
   ],
   "source": [
    "num_epochs = int(1e4)\n",
    "display_epochs = int(1e3)\n",
    "\n",
    "obj_vals= []\n",
    "\n",
    "inputs = torch.from_numpy(np.array(train_data.transpose()))\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10): \n",
    "    for i in range(len(train_data.columns)):\n",
    "        #input_temp = torch.reshape(inputs[i].float(), (1,-1))\n",
    "        input_temp = inputs[i].float()\n",
    "#         print(input_temp)\n",
    "         \n",
    "        input_temp = input_temp.to(device)\n",
    "        target_temp = one_hot(train_labels[i], one_hot_matrix)\n",
    "        target_temp = target_temp.to(device).float()\n",
    "        #target_temp = torch.reshape(target_temp, (1,-1)).float()\n",
    "#         print(target_temp)\n",
    "#         print('\\n')\n",
    "        optimizer.zero_grad()\n",
    "        obj_val = loss(model.forward(input_temp), )\n",
    "#         print(model.forward(input_temp))\n",
    "#         print('\\n')\n",
    "        \n",
    "         # clear any previous gradients  \n",
    "        obj_val.backward() # backprop step, calculates gradient values\n",
    "        optimizer.step() # apply gradients to model parameters\n",
    "#         print(obj_val.item())\n",
    "#         print('\\n')\n",
    "        obj_vals.append(obj_val.item())\n",
    "    print(f'Epoch [{epoch}/{10}]\\tLoss: {obj_val.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(test_data.columns)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26492, 196])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9333,\n",
       "        0.9922, 0.9882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0392, 0.8784, 0.9922, 0.9882, 0.9882, 0.9922, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9333, 0.9922,\n",
       "        0.9922, 0.9922, 0.7412, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.6471, 0.9922, 0.9882, 0.2941, 0.4745, 0.0000, 0.9922,\n",
       "        0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.9882, 0.9412,\n",
       "        0.1098, 0.0000, 0.0000, 0.0000, 0.9922, 0.7647, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.9647, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        1.0000, 0.7686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9882, 0.9020,\n",
       "        0.0000, 0.0000, 0.0000, 0.0275, 0.9882, 0.9922, 0.0471, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.9922, 0.8824, 0.0000, 0.0000, 0.4471, 0.9922,\n",
       "        0.9882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9882,\n",
       "        0.9882, 0.8980, 0.9882, 0.9922, 0.8745, 0.2196, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.7804, 0.9882, 0.9922, 0.9882, 0.5686,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
